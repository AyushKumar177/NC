{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91975\\anaconda3\\envs\\langchain\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "model_name = \"gpt2\"  \n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Write article on The future of artificial intelligence in healthcare \"\n",
    "\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs, \n",
    "    max_length=500, \n",
    "    do_sample=True, \n",
    "    top_k=50,     \n",
    "    top_p=0.95,    \n",
    "    temperature=0.7, \n",
    "    num_return_sequences=1 \n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write article on The future of artificial intelligence in healthcare is up in the air.\n",
      "\n",
      "The National Science Foundation is working to develop a computer system to analyze the scientific literature, and its research aims to develop a new model of how artificial intelligence is being used in medicine.\n",
      "\n",
      "A new version of the computer system will be developed by the National Institutes of Health, to help scientists develop better artificial intelligence algorithms.\n",
      "\n",
      "But, it's already being tested at the federal level, where it will be used to study the effects of drug development on the health of millions of people.\n",
      "\n",
      "This is the first time that a system that was developed in a laboratory to study the effects of drugs has been used in a clinical trial.\n",
      "\n",
      "In 2013, for instance, researchers from the University of California, Berkeley and the University of California, Irvine developed a system that could predict how much blood pressure would drop with every dose of an injection of one of three different types of drug.\n",
      "\n",
      "They found that the system would predict a similar effect in patients taking the most common drugs as well as those taking the least common drugs.\n",
      "\n",
      "The system, known as the SENS, is expected to be in clinical trials soon.\n",
      "\n",
      "The researchers said it was a \"very exciting time\" for the field, but said it was still far from complete.\n",
      "\n",
      "\"We have a lot of work to do before we can really start thinking about how to apply it to our clinical trials,\" Dr. Mark C. Miller, director of the National Center for Advancing Translational Sciences at the University of California, San Diego, told Reuters.\n",
      "\n",
      "\"We're still in the process of figuring out how it will work in humans.\"\n",
      "\n",
      "The system will be used in a clinical trial, but it may not be ready until the end of the year, the researchers said.\n",
      "\n",
      "The idea is that the system will help doctors diagnose and treat patients who are experiencing rapid changes in their blood pressure, which can lead to a blood sugar spike.\n",
      "\n",
      "\"In the long run, this could be used to help patients who are suffering from diabetes,\" said Dr. Mark C. Miller, director of the National Center for Advancing Translational Sciences at the University of California, San Diego.\n",
      "\n",
      "Miller said the system could be used for two reasons: first, it can be used to diagnose and treat a patient who is experiencing rapid changes in blood pressure.\n",
      "\n",
      "The system can\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 132.33787536621094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate perplexity\n",
    "loss = model(inputs, labels=inputs)[\"loss\"]\n",
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
